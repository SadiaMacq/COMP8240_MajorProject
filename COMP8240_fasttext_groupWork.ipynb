{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Project COMP8240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Project - Group J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Sadia Tasnim (45760179)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  fastText library exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to explore the facebook machine learning library called fastText which is doing a phenomenal job in word labelling and representation. This particular machine learning library can be applied to the purpose of text classification which is a necessity in case of sentiment analysis, business analysis (such as - product reviews, customer satisfaction percentage), as well as political situation analysis. In this project we will show our work in two steps - \n",
    "1. Replication of original work\n",
    "2. Applying fasttext model in new dataset and comparison with the original work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is to show how the library can be used in supervised machine learning and even be tuned to be fast and more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter data sources\n",
    "1. http://cucis.ece.northwestern.edu/projects/Social/sentiment_data.html\n",
    "2. http://help.sentiment140.com/for-students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter dataset from the above mentioned first link have two separate files for twitter data and labels.The purpose is to combine those the two text files so that the labels for each tweet can be viewed in one line and the model setup in fasttext can be completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken the second dataset to enrich the volume and variety of the dataset as the first dataset had only 500 tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will combine the tweets and the labels of the first data source\n",
    "combine =[]\n",
    "\n",
    "with open(\"tweets_data.txt\") as xh:\n",
    "    with open('tweets_label.txt') as yh:\n",
    "        with open(\"tweetsShort.txt\",\"w\") as zh:\n",
    "      #Read first file\n",
    "          xlines = xh.readlines()\n",
    "      #Read second file\n",
    "          ylines = yh.readlines()\n",
    "      #Combine content of both lists\n",
    "      #combine = list(zip(ylines,xlines))\n",
    "      #Write to third file\n",
    "          for i in range(len(xlines)):\n",
    "            line = \"__label__\"+ ylines[i].strip() + ' ' + xlines[i]\n",
    "            zh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735969</th>\n",
       "      <td>0</td>\n",
       "      <td>2264907016</td>\n",
       "      <td>Sun Jun 21 05:16:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>aimrere</td>\n",
       "      <td>headache now coz this prblem ! am not a rebel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588842</th>\n",
       "      <td>0</td>\n",
       "      <td>2216790764</td>\n",
       "      <td>Wed Jun 17 19:58:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>krisshuntx3</td>\n",
       "      <td>@sicknastyemily aww thanks! But i think i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888346</th>\n",
       "      <td>4</td>\n",
       "      <td>1687276371</td>\n",
       "      <td>Sun May 03 08:15:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Laurabartleyy</td>\n",
       "      <td>gettin ready for work!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400927</th>\n",
       "      <td>4</td>\n",
       "      <td>2054470446</td>\n",
       "      <td>Sat Jun 06 07:25:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lgreps</td>\n",
       "      <td>just enjoyed the best 2 hour work out ever. we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845770</th>\n",
       "      <td>4</td>\n",
       "      <td>1564282388</td>\n",
       "      <td>Mon Apr 20 02:43:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>parasight</td>\n",
       "      <td>What a hilarious music video.  Mickey 3D - Mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "735969        0  2264907016  Sun Jun 21 05:16:35 PDT 2009  NO_QUERY   \n",
       "588842        0  2216790764  Wed Jun 17 19:58:28 PDT 2009  NO_QUERY   \n",
       "888346        4  1687276371  Sun May 03 08:15:31 PDT 2009  NO_QUERY   \n",
       "1400927       4  2054470446  Sat Jun 06 07:25:25 PDT 2009  NO_QUERY   \n",
       "845770        4  1564282388  Mon Apr 20 02:43:02 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "735969         aimrere  headache now coz this prblem ! am not a rebel ...  \n",
       "588842     krisshuntx3  @sicknastyemily aww thanks! But i think i have...  \n",
       "888346   Laurabartleyy                           gettin ready for work!!   \n",
       "1400927         lgreps  just enjoyed the best 2 hour work out ever. we...  \n",
       "845770       parasight  What a hilarious music video.  Mickey 3D - Mat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code will read tweets from the second dataset\n",
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "tweet_long_df = pd.read_csv('trainingandtestdata/tweetTraining.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "tweet_long_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only the tweets \n",
    "tweet_long_df_new = tweet_long_df.filter(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  is upset that he can't update his Facebook by ...\n",
       "2  @Kenichan I dived many times for the ball. Man...\n",
       "3    my whole body feels itchy and like its on fire \n",
       "4  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the dataframe\n",
    "tweet_long_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the tweets (every tweet in a new line) in a text file\n",
    "tweet_long_df_new.to_csv('longTweet.txt', sep='\\n', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only the labels\n",
    "tweet_long_df_new_label = tweet_long_df.filter(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset description, the polarity of the tweets are saved in numeric form. 0 = negative, 2 = neutral, 4 = positive. However, the dataset from link 1 saves the polarity as such- N = negative, O = neutral, P = positive. To make the datasets of the same format, I am changing the polarity of the second dataset according to the first dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 0), 'target'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 2), 'target'] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 4), 'target'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target\n",
       "0            N\n",
       "1            N\n",
       "2            N\n",
       "3            N\n",
       "4            N\n",
       "...        ...\n",
       "1599995      P\n",
       "1599996      P\n",
       "1599997      P\n",
       "1599998      P\n",
       "1599999      P\n",
       "\n",
       "[1600000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_long_df_new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the label tweets (every tweet in a new line) in a text file\n",
    "tweet_long_df_new_label.to_csv('twitterLabelBig.txt', sep='\\n', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to merge the tweets from the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to merge two files \n",
    "dataTweet = dataTweet2 = \"\" \n",
    "  \n",
    "# Reading data from first file \n",
    "with open('tweets_data.txt', errors='ignore') as fp: \n",
    "    dataTweet = fp.read() \n",
    "    with open('longTweet.txt', errors='ignore') as fp: \n",
    "        dataTweet2 = fp.read() \n",
    "# Merging two files into one another file \n",
    "dataTweet += \"\\n\"\n",
    "dataTweet += dataTweet2 \n",
    "with open ('totalTweet.txt', 'w') as fp: \n",
    "    fp.write(dataTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merging the labels from the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to merge two files \n",
    "dataTweet = dataTweet2 = \"\" \n",
    "  \n",
    "# Reading data from first file \n",
    "with open('tweets_label.txt', errors='ignore') as fp: \n",
    "    dataTweet = fp.read() \n",
    "    with open('twitterLabelBig.txt', errors='ignore') as fp: \n",
    "        dataTweet2 = fp.read() \n",
    "# Merging two files into one another file \n",
    "dataTweet += \"\\n\"\n",
    "dataTweet += dataTweet2 \n",
    "with open ('totalLabel.txt', 'w') as fp: \n",
    "    fp.write(dataTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step combines the tweets with their polarity value. The prefix \"__label__\" is necessary for the fasttext format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine =[]\n",
    "\n",
    "with open(\"totalTweet.txt\") as xh:\n",
    "    with open('totalLabel.txt') as yh:\n",
    "        with open(\"totalLabelledTweet.txt\",\"w\") as zh:\n",
    "      #Read first file\n",
    "          xlines = xh.readlines()\n",
    "      #Read second file\n",
    "          ylines = yh.readlines()\n",
    "      #Combine content of both lists\n",
    "      #combine = list(zip(ylines,xlines))\n",
    "      #Write to third file\n",
    "          for i in range(len(xlines)):\n",
    "            line = \"__label__\"+ ylines[i].strip() + ' ' + xlines[i]\n",
    "            zh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command line code \"wc totalLabelledTweet.txt\" will give us the result of the word counts, line counts information which is in my case is 1600500 (line count or in this case number of tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to divide the datasets into train and test sets. I have created tweet.train and tweet.valid sets for training and testing purpose respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing fasttext library\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_supervised() will mostly be used for retruning a model object and calling test and predict on that object. This is the same as learning the text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"tweet.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input argument indicates the file containing the training examples. We can now use the model variable to access information on the trained model.\n",
    "\n",
    "We can also call save_model to save it as a file and load it later with load_model function.\n",
    "<br>source: https://fasttext.cc/docs/en/supervised-tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"model_tweet.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the classifier, model.predict() is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__P',), array([0.98308438]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Because I'm happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As happy is a positive word, it is labelled as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__P',), array([0.96914047]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"best\" is a positive word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__N',), array([1.00000954]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I am sad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smilarly \"sad\" is a word discribing negative emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to test the model's quality on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6430884495317378, 0.6430884495317378)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"tweet.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output are the number of samples (here 480500), the precision at one (0.643) and the recall at one (0.643)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.3333333333333333, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"tweet.valid\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision at 5 is 0.333 and recall is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know that, precision discloses the number of correct labels among the labels predicted by fastText and the recall score is the number of successfully predicted labels among all the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__P', '__label__N', '__label__O'),\n",
       " array([9.83084381e-01, 1.69356670e-02, 1.00003181e-05]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Because I'm happy\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Betterment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A crude normalization can be obtained using the command line tools such as sed and tr and by using that, I removed the uppercase and punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, I tried to train the new model on that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preprocssed = fasttext.train_supervised(input=\"tweetL.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.12849947970863684, 0.12849947970863684)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preprocssed.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model betterment through increased epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_epochs = fasttext.train_supervised(input=\"tweetL.train\", epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.7870697190426639, 0.7870697190426639)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_epochs.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After increasing the number of epochs the model became quite strong. By setting up the epoch option, I increased the number of times each example is seen from default value 5 to 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up larger learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_lr = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6340457856399584, 0.6340457856399584)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision and recall score gets a bit down from the scores of increased epoch ( around 19%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_lr1 = fasttext.train_supervised(input=\"tweetL.train\", lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.43113423517169613, 0.43113423517169613)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr1.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know the range of lr is from 0.1 to 1.0. By applying lr=0.5, I could see that the scores decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying learing rate and increased epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.5827825182101977, 0.5827825182101977)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of sentiment analysis, using bigrams can be beneficial as word order can effect the accuracy of sentiment analysis. For example, In the sentence- \"I am not good at accounting.\" has the word \"good\" in it, it might be declared as positive but, using bigrams can be useful here as the word order \"not good\" will be taken into account and deemed as negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bigram = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6259791883454735, 0.6259791883454735)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bigram.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential solution for faster training is to use hierarchical softmax instead of the regular softmax. This can be utilised with the option -loss hs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hisoftmax = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='hs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.802834547346514, 0.802834547346514)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hisoftmax.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase rate in precision from bigram to Hierarchical softmax is 22.06% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchical softmax is a loss function that approximates the softmax with a much faster computation.\n",
    "\n",
    "The idea is to build a binary tree whose leaves correspond to the labels. Each intermediate node has a binary decision activation (e.g. sigmoid) that is trained, and predicts if we should go to the left or to the right. The probability of the output unit is then given by the product of the probabilities of intermediate nodes along the path from the root to the output unit leave.\n",
    "\n",
    "For a detailed explanation, you can have a look on this video.\n",
    "\n",
    "In fastText, we use a Huffman tree, so that the lookup time is faster for more frequent outputs and thus the average lookup time for the output is optimal.\n",
    "<br>\n",
    "Data Source: https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is beneficial when we want to assign multiple labels to the document. When we use independent binary classifiers for each label, it creates a convenient environment to handle multple labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiClass= fasttext.train_supervised(input=\"tweetL.train\", lr=0.5, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__n',), array([1.00001001]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multiClass.predict(\"because I'm not happy\", k=-1, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.3333333333333333, 1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multiClass.test(\"tweetL.valid\", k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it shows that we are getting recall score 1.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
