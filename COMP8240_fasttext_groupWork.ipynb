{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Project COMP8240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Project - Group J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Sadia Tasnim (45760179)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  fastText library exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to explore the facebook machine learning library called fastText which is doing a phenomenal job in word labelling and representation. This particular machine learning library can be applied to the purpose of text classification which is a necessity in case of sentiment analysis, business analysis (such as - product reviews, customer satisfaction percentage), as well as political situation analysis. In this project we will show our work in two steps - \n",
    "1. Replication of original work\n",
    "2. Applying fasttext model in new dataset and comparison with the original work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is to show how the library can be used in supervised machine learning and even be tuned to be fast and more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter data sources\n",
    "1. http://cucis.ece.northwestern.edu/projects/Social/sentiment_data.html\n",
    "2. http://help.sentiment140.com/for-students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter dataset from the above mentioned first link have two separate files for twitter data and labels.The purpose is to combine those the two text files so that the labels for each tweet can be viewed in one line and the model setup in fasttext can be completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken the second dataset to enrich the volume and variety of the dataset as the first dataset had only 500 tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will combine the tweets and the labels of the first data source\n",
    "combine =[]\n",
    "\n",
    "with open(\"tweets_data.txt\") as xh:\n",
    "    with open('tweets_label.txt') as yh:\n",
    "        with open(\"tweetsShort.txt\",\"w\") as zh:\n",
    "      #Read first file\n",
    "          xlines = xh.readlines()\n",
    "      #Read second file\n",
    "          ylines = yh.readlines()\n",
    "      #Combine content of both lists\n",
    "      #combine = list(zip(ylines,xlines))\n",
    "      #Write to third file\n",
    "          for i in range(len(xlines)):\n",
    "            line = \"__label__\"+ ylines[i].strip() + ' ' + xlines[i]\n",
    "            zh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1029879</th>\n",
       "      <td>4</td>\n",
       "      <td>1932844434</td>\n",
       "      <td>Tue May 26 22:21:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>morgancorin</td>\n",
       "      <td>Sleep...who needs it?!? At least I'll have a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111585</th>\n",
       "      <td>0</td>\n",
       "      <td>1825172728</td>\n",
       "      <td>Sun May 17 04:39:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Jovanny987</td>\n",
       "      <td>Wasent On 4 Some Time Cuz I Was qrounded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486161</th>\n",
       "      <td>0</td>\n",
       "      <td>2181412693</td>\n",
       "      <td>Mon Jun 15 11:47:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ewabradley</td>\n",
       "      <td>is a little lost today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474408</th>\n",
       "      <td>4</td>\n",
       "      <td>2065731319</td>\n",
       "      <td>Sun Jun 07 09:10:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Nattington</td>\n",
       "      <td>so pleased Roger did it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200171</th>\n",
       "      <td>4</td>\n",
       "      <td>1985453394</td>\n",
       "      <td>Sun May 31 17:07:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BethHeinbeck</td>\n",
       "      <td>Excited to watch the VMA's and see Kings of Le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "1029879       4  1932844434  Tue May 26 22:21:12 PDT 2009  NO_QUERY   \n",
       "111585        0  1825172728  Sun May 17 04:39:35 PDT 2009  NO_QUERY   \n",
       "486161        0  2181412693  Mon Jun 15 11:47:42 PDT 2009  NO_QUERY   \n",
       "1474408       4  2065731319  Sun Jun 07 09:10:49 PDT 2009  NO_QUERY   \n",
       "1200171       4  1985453394  Sun May 31 17:07:55 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \n",
       "1029879   morgancorin  Sleep...who needs it?!? At least I'll have a c...  \n",
       "111585     Jovanny987          Wasent On 4 Some Time Cuz I Was qrounded   \n",
       "486161     ewabradley                         is a little lost today...   \n",
       "1474408    Nattington                           so pleased Roger did it   \n",
       "1200171  BethHeinbeck  Excited to watch the VMA's and see Kings of Le...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code will read tweets from the second dataset\n",
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "tweet_long_df = pd.read_csv('trainingandtestdata/tweetTraining.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "tweet_long_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1188305</th>\n",
       "      <td>4</td>\n",
       "      <td>1983310328</td>\n",
       "      <td>Sun May 31 12:54:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alixfersure</td>\n",
       "      <td>Its to early. So I'm gonna try go back to sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433502</th>\n",
       "      <td>4</td>\n",
       "      <td>2060455872</td>\n",
       "      <td>Sat Jun 06 18:56:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Joey_P_Golf</td>\n",
       "      <td>@TheChristinaKim give me a month or two to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071103</th>\n",
       "      <td>4</td>\n",
       "      <td>1966268307</td>\n",
       "      <td>Fri May 29 17:26:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ashleyepsen</td>\n",
       "      <td>#blackkeys, #muchbetter &amp;amp; #heybaby are my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411907</th>\n",
       "      <td>0</td>\n",
       "      <td>2060223185</td>\n",
       "      <td>Sat Jun 06 18:29:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>charlotte3107</td>\n",
       "      <td>@R1OTboy o.O whatt? explain???  iloveyuophilly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525090</th>\n",
       "      <td>0</td>\n",
       "      <td>2193746724</td>\n",
       "      <td>Tue Jun 16 08:52:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tylermasid</td>\n",
       "      <td>I wish  I don't want to audits!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "1188305       4  1983310328  Sun May 31 12:54:45 PDT 2009  NO_QUERY   \n",
       "1433502       4  2060455872  Sat Jun 06 18:56:25 PDT 2009  NO_QUERY   \n",
       "1071103       4  1966268307  Fri May 29 17:26:53 PDT 2009  NO_QUERY   \n",
       "411907        0  2060223185  Sat Jun 06 18:29:50 PDT 2009  NO_QUERY   \n",
       "525090        0  2193746724  Tue Jun 16 08:52:33 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "1188305    alixfersure   Its to early. So I'm gonna try go back to sleep   \n",
       "1433502    Joey_P_Golf  @TheChristinaKim give me a month or two to get...  \n",
       "1071103    ashleyepsen  #blackkeys, #muchbetter &amp; #heybaby are my ...  \n",
       "411907   charlotte3107  @R1OTboy o.O whatt? explain???  iloveyuophilly...  \n",
       "525090      tylermasid                 I wish  I don't want to audits!!!   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "tweet_df = pd.read_csv('trainingandtestdata/tweetTraining.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "tweet_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.loc[(tweet_df.target == 0), 'target'] = 'Negative'\n",
    "tweet_df.loc[(tweet_df.target == 2), 'target'] = 'Neutral'\n",
    "tweet_df.loc[(tweet_df.target == 4), 'target'] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAFSCAYAAACpJEghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAenklEQVR4nO3dfbBd1X2f8edrKcb4BSxhwTASWKSoToHEdlAFiT1pEzmSnHQskoFEqVM0GSVKCW2cl5kUMmnVwGhqmrY0pIUJMSqCpgGFxoGmwVgVcT2ZoYCwnWDAVKqxQUEF2VfBJB6wRX7946xbjq4v916E7LPuuc9n5sze+7fXWmedGXz91d57nZOqQpIkSX153agnIEmSpG9kSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnq0OJRT+B4e9vb3lYrV64c9TQkSZJm9dBDD32pqpZNd27sQtrKlSvZu3fvqKchSZI0qyRffKVz3u6UJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA7NKaQl+cUkjyT5bJLfS/KGJEuT7E6yr22XDLW/Msn+JI8nWT9UPz/Jw+3cdUnS6ickub3V70+ycqjP5vYe+5JsPo6fXZIkqVuzhrQky4GfB1ZX1XnAImATcAWwp6pWAXvaMUnOaefPBTYA1ydZ1Ia7AdgKrGqvDa2+BThcVWcD1wLXtLGWAtuAC4A1wLbhMChJkjSu5nq7czFwYpLFwBuBp4GNwM52fidwUdvfCNxWVS9W1RPAfmBNktOBk6rqvqoq4JYpfSbHugNY266yrQd2V9VEVR0GdvNysJMkSRpbs4a0qvoL4N8ATwIHgeeq6uPAaVV1sLU5CJzauiwHnhoa4kCrLW/7U+tH9amqI8BzwCkzjCVJkjTWZv3tznZ7cSNwFvCXwO8n+cmZukxTqxnqx9pneI5bGdxG5cwzz5xhagvXyiv++6inoHnkCx/+4VFPQfOEf1v0avi35dWZy+3O9wFPVNWhqvo68AfA9wLPtFuYtO2zrf0B4Iyh/isY3B490Pan1o/q026pngxMzDDWUarqxqpaXVWrly2b9ofkJUmS5pW5hLQngQuTvLE9J7YWeAy4C5hcbbkZuLPt3wVsais2z2KwQOCBdkv0+SQXtnEundJncqyLgXvbc2v3AOuSLGlX9Na1miRJ0lib9XZnVd2f5A7gU8AR4NPAjcCbgV1JtjAIcpe09o8k2QU82tpfXlUvteEuA24GTgTubi+Am4Bbk+xncAVtUxtrIsnVwIOt3VVVNfGaPrEkSdI8MGtIA6iqbQy+CmPYiwyuqk3XfjuwfZr6XuC8aeov0ELeNOd2ADvmMk9JkqRx4S8OSJIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElSh2YNaUnekeQzQ6+vJPmFJEuT7E6yr22XDPW5Msn+JI8nWT9UPz/Jw+3cdUnS6ickub3V70+ycqjP5vYe+5JsPs6fX5IkqUuzhrSqeryq3lVV7wLOB74KfBS4AthTVauAPe2YJOcAm4BzgQ3A9UkWteFuALYCq9prQ6tvAQ5X1dnAtcA1baylwDbgAmANsG04DEqSJI2rV3u7cy3wf6rqi8BGYGer7wQuavsbgduq6sWqegLYD6xJcjpwUlXdV1UF3DKlz+RYdwBr21W29cDuqpqoqsPAbl4OdpIkSWPr1Ya0TcDvtf3TquogQNue2urLgaeG+hxoteVtf2r9qD5VdQR4DjhlhrEkSZLG2pxDWpLXAx8Afn+2ptPUaob6sfYZntvWJHuT7D106NAs05MkSerfq7mS9n7gU1X1TDt+pt3CpG2fbfUDwBlD/VYAT7f6imnqR/VJshg4GZiYYayjVNWNVbW6qlYvW7bsVXwkSZKkPr2akPYTvHyrE+AuYHK15WbgzqH6prZi8ywGCwQeaLdEn09yYXve7NIpfSbHuhi4tz23dg+wLsmStmBgXatJkiSNtcVzaZTkjcAPAj87VP4wsCvJFuBJ4BKAqnokyS7gUeAIcHlVvdT6XAbcDJwI3N1eADcBtybZz+AK2qY21kSSq4EHW7urqmriGD6nJEnSvDKnkFZVX2XwIP9w7csMVntO1347sH2a+l7gvGnqL9BC3jTndgA75jJPSZKkceEvDkiSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR2aU0hL8tYkdyT5XJLHknxPkqVJdifZ17ZLhtpfmWR/kseTrB+qn5/k4XbuuiRp9ROS3N7q9ydZOdRnc3uPfUk2H8fPLkmS1K25Xkn7TeBjVfUdwDuBx4ArgD1VtQrY045Jcg6wCTgX2ABcn2RRG+cGYCuwqr02tPoW4HBVnQ1cC1zTxloKbAMuANYA24bDoCRJ0riaNaQlOQn4PuAmgKr6WlX9JbAR2Nma7QQuavsbgduq6sWqegLYD6xJcjpwUlXdV1UF3DKlz+RYdwBr21W29cDuqpqoqsPAbl4OdpIkSWNrLlfSvh04BPynJJ9O8pEkbwJOq6qDAG17amu/HHhqqP+BVlve9qfWj+pTVUeA54BTZhhLkiRprM0lpC0Gvhu4oareDfw17dbmK8g0tZqhfqx9Xn7DZGuSvUn2Hjp0aIapSZIkzQ9zCWkHgANVdX87voNBaHum3cKkbZ8dan/GUP8VwNOtvmKa+lF9kiwGTgYmZhjrKFV1Y1WtrqrVy5Ytm8NHkiRJ6tusIa2q/i/wVJJ3tNJa4FHgLmByteVm4M62fxewqa3YPIvBAoEH2i3R55Nc2J43u3RKn8mxLgbubc+t3QOsS7KkLRhY12qSJEljbfEc2/1T4HeTvB74PPBTDALeriRbgCeBSwCq6pEkuxgEuSPA5VX1UhvnMuBm4ETg7vaCwaKEW5PsZ3AFbVMbayLJ1cCDrd1VVTVxjJ9VkiRp3phTSKuqzwCrpzm19hXabwe2T1PfC5w3Tf0FWsib5twOYMdc5ilJkjQu/MUBSZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnq0JxCWpIvJHk4yWeS7G21pUl2J9nXtkuG2l+ZZH+Sx5OsH6qf38bZn+S6JGn1E5Lc3ur3J1k51Gdze499STYft08uSZLUsVdzJe37q+pdVbW6HV8B7KmqVcCedkySc4BNwLnABuD6JItanxuArcCq9trQ6luAw1V1NnAtcE0baymwDbgAWANsGw6DkiRJ4+q13O7cCOxs+zuBi4bqt1XVi1X1BLAfWJPkdOCkqrqvqgq4ZUqfybHuANa2q2zrgd1VNVFVh4HdvBzsJEmSxtZcQ1oBH0/yUJKtrXZaVR0EaNtTW3058NRQ3wOttrztT60f1aeqjgDPAafMMJYkSdJYWzzHdu+pqqeTnArsTvK5GdpmmlrNUD/WPi+/4SA4bgU488wzZ5iaJEnS/DCnK2lV9XTbPgt8lMHzYc+0W5i07bOt+QHgjKHuK4CnW33FNPWj+iRZDJwMTMww1tT53VhVq6tq9bJly+bykSRJkro2a0hL8qYkb5ncB9YBnwXuAiZXW24G7mz7dwGb2orNsxgsEHig3RJ9PsmF7XmzS6f0mRzrYuDe9tzaPcC6JEvagoF1rSZJkjTW5nK78zTgo+3bMhYD/6WqPpbkQWBXki3Ak8AlAFX1SJJdwKPAEeDyqnqpjXUZcDNwInB3ewHcBNyaZD+DK2ib2lgTSa4GHmztrqqqidfweSVJkuaFWUNaVX0eeOc09S8Da1+hz3Zg+zT1vcB509RfoIW8ac7tAHbMNk9JkqRx4i8OSJIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHZpzSEuyKMmnk/xRO16aZHeSfW27ZKjtlUn2J3k8yfqh+vlJHm7nrkuSVj8hye2tfn+SlUN9Nrf32Jdk83H51JIkSZ17NVfSPgQ8NnR8BbCnqlYBe9oxSc4BNgHnAhuA65Msan1uALYCq9prQ6tvAQ5X1dnAtcA1baylwDbgAmANsG04DEqSJI2rOYW0JCuAHwY+MlTeCOxs+zuBi4bqt1XVi1X1BLAfWJPkdOCkqrqvqgq4ZUqfybHuANa2q2zrgd1VNVFVh4HdvBzsJEmSxtZcr6T9e+BXgL8Zqp1WVQcB2vbUVl8OPDXU7kCrLW/7U+tH9amqI8BzwCkzjHWUJFuT7E2y99ChQ3P8SJIkSf2aNaQl+QfAs1X10BzHzDS1mqF+rH1eLlTdWFWrq2r1smXL5jhNSZKkfs3lStp7gA8k+QJwG/ADSf4z8Ey7hUnbPtvaHwDOGOq/Ani61VdMUz+qT5LFwMnAxAxjSZIkjbVZQ1pVXVlVK6pqJYMFAfdW1U8CdwGTqy03A3e2/buATW3F5lkMFgg80G6JPp/kwva82aVT+kyOdXF7jwLuAdYlWdIWDKxrNUmSpLG2+DX0/TCwK8kW4EngEoCqeiTJLuBR4AhweVW91PpcBtwMnAjc3V4ANwG3JtnP4ArapjbWRJKrgQdbu6uqauI1zFmSJGleeFUhrao+AXyi7X8ZWPsK7bYD26ep7wXOm6b+Ai3kTXNuB7Dj1cxTkiRpvvMXByRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOzhrQkb0jyQJI/S/JIkl9v9aVJdifZ17ZLhvpcmWR/kseTrB+qn5/k4XbuuiRp9ROS3N7q9ydZOdRnc3uPfUk2H9dPL0mS1Km5XEl7EfiBqnon8C5gQ5ILgSuAPVW1CtjTjklyDrAJOBfYAFyfZFEb6wZgK7CqvTa0+hbgcFWdDVwLXNPGWgpsAy4A1gDbhsOgJEnSuJo1pNXAX7XDb2uvAjYCO1t9J3BR298I3FZVL1bVE8B+YE2S04GTquq+qirglil9Jse6A1jbrrKtB3ZX1URVHQZ283KwkyRJGltzeiYtyaIknwGeZRCa7gdOq6qDAG17amu+HHhqqPuBVlve9qfWj+pTVUeA54BTZhhLkiRprM0ppFXVS1X1LmAFg6ti583QPNMNMUP9WPu8/IbJ1iR7k+w9dOjQDFOTJEmaH17V6s6q+kvgEwxuOT7TbmHSts+2ZgeAM4a6rQCebvUV09SP6pNkMXAyMDHDWFPndWNVra6q1cuWLXs1H0mSJKlLc1nduSzJW9v+icD7gM8BdwGTqy03A3e2/buATW3F5lkMFgg80G6JPp/kwva82aVT+kyOdTFwb3tu7R5gXZIlbcHAulaTJEkaa4vn0OZ0YGdbofk6YFdV/VGS+4BdSbYATwKXAFTVI0l2AY8CR4DLq+qlNtZlwM3AicDd7QVwE3Brkv0MrqBtamNNJLkaeLC1u6qqJl7LB5YkSZoPZg1pVfXnwLunqX8ZWPsKfbYD26ep7wW+4Xm2qnqBFvKmObcD2DHbPCVJksaJvzggSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdmjWkJTkjyZ8keSzJI0k+1OpLk+xOsq9tlwz1uTLJ/iSPJ1k/VD8/ycPt3HVJ0uonJLm91e9PsnKoz+b2HvuSbD6un16SJKlTc7mSdgT45ar6O8CFwOVJzgGuAPZU1SpgTzumndsEnAtsAK5PsqiNdQOwFVjVXhtafQtwuKrOBq4FrmljLQW2ARcAa4Btw2FQkiRpXM0a0qrqYFV9qu0/DzwGLAc2Ajtbs53ARW1/I3BbVb1YVU8A+4E1SU4HTqqq+6qqgFum9Jkc6w5gbbvKth7YXVUTVXUY2M3LwU6SJGlsvapn0tptyHcD9wOnVdVBGAQ54NTWbDnw1FC3A622vO1PrR/Vp6qOAM8Bp8wwliRJ0libc0hL8mbgvwK/UFVfmanpNLWaoX6sfYbntjXJ3iR7Dx06NMPUJEmS5oc5hbQk38YgoP1uVf1BKz/TbmHSts+2+gHgjKHuK4CnW33FNPWj+iRZDJwMTMww1lGq6saqWl1Vq5ctWzaXjyRJktS1uazuDHAT8FhV/buhU3cBk6stNwN3DtU3tRWbZzFYIPBAuyX6fJIL25iXTukzOdbFwL3tubV7gHVJlrQFA+taTZIkaawtnkOb9wD/CHg4yWda7VeBDwO7kmwBngQuAaiqR5LsAh5lsDL08qp6qfW7DLgZOBG4u71gEAJvTbKfwRW0TW2siSRXAw+2dldV1cSxfVRJkqT5Y9aQVlV/yvTPhgGsfYU+24Ht09T3AudNU3+BFvKmObcD2DHbPCVJksaJvzggSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1aNaQlmRHkmeTfHaotjTJ7iT72nbJ0Lkrk+xP8niS9UP185M83M5dlyStfkKS21v9/iQrh/psbu+xL8nm4/apJUmSOjeXK2k3Axum1K4A9lTVKmBPOybJOcAm4NzW5/oki1qfG4CtwKr2mhxzC3C4qs4GrgWuaWMtBbYBFwBrgG3DYVCSJGmczRrSquqTwMSU8kZgZ9vfCVw0VL+tql6sqieA/cCaJKcDJ1XVfVVVwC1T+kyOdQewtl1lWw/srqqJqjoM7OYbw6IkSdJYOtZn0k6rqoMAbXtqqy8Hnhpqd6DVlrf9qfWj+lTVEeA54JQZxpIkSRp7x3vhQKap1Qz1Y+1z9JsmW5PsTbL30KFDc5qoJElSz441pD3TbmHSts+2+gHgjKF2K4CnW33FNPWj+iRZDJzM4PbqK431DarqxqpaXVWrly1bdowfSZIkqR/HGtLuAiZXW24G7hyqb2orNs9isEDggXZL9PkkF7bnzS6d0mdyrIuBe9tza/cA65IsaQsG1rWaJEnS2Fs8W4Mkvwf8feBtSQ4wWHH5YWBXki3Ak8AlAFX1SJJdwKPAEeDyqnqpDXUZg5WiJwJ3txfATcCtSfYzuIK2qY01keRq4MHW7qqqmrqAQZIkaSzNGtKq6ide4dTaV2i/Hdg+TX0vcN409RdoIW+aczuAHbPNUZIkadz4iwOSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktSheRHSkmxI8niS/UmuGPV8JEmSvtm6D2lJFgH/EXg/cA7wE0nOGe2sJEmSvrm6D2nAGmB/VX2+qr4G3AZsHPGcJEmSvqnmQ0hbDjw1dHyg1SRJksbW4lFPYA4yTa2OapBsBba2w79K8vg3fVYaF28DvjTqSfQm14x6BtK859+Wafi3ZVpvf6UT8yGkHQDOGDpeATw93KCqbgRu/FZOSuMhyd6qWj3qeUgaL/5t0fEwH253PgisSnJWktcDm4C7RjwnSZKkb6rur6RV1ZEk/wS4B1gE7KiqR0Y8LUmSpG+q7kMaQFX9MfDHo56HxpK3ySV9M/i3Ra9Zqmr2VpIkSfqWmg/PpEmSJC04hjRJkqQOGdIkSZI6ZEjTgpTk7Une1/ZPTPKWUc9J0vyW5G8n2ZPks+34u5L82qjnpfnLkKYFJ8nPAHcAv91KK4A/HNmEJI2L3wGuBL4OUFV/zuC7PaVjYkjTQnQ58B7gKwBVtQ84daQzkjQO3lhVD0ypHRnJTDQWDGlaiF6sqq9NHiRZzJTfg5WkY/ClJH+L9vckycXAwdFOSfPZvPgyW+k4+59JfhU4MckPAj8H/LcRz0nS/Hc5gy+x/Y4kfwE8AXxwtFPSfOaX2WrBSfI6YAuwDgiDnxz7SPk/BkmvQZJFVfVSkjcBr6uq50c9J81vhjQtOEl+BPjjqnpx1HORND6SPAl8DLgduNd/+Om18pk0LUQfAP53kluT/HB7Jk2SXqt3AP+DwW3PJ5L8hyTvHfGcNI95JU0LUpJvA94P/DjwXmB3Vf30aGclaVwkWQL8JvDBqlo06vlofvJKmhakqvo6cDdwG/AQsHG0M5I0DpL8vSTXA58C3gD82IinpHnMK2lacJJsYPAFk98PfILB8yMfryq/z0jSMUvyBPAZYBdwV1X99WhnpPnOkKYFJ8ltDK6g3e3iAUnHS5KTquoro56HxochTZKk1yDJr1TVv07yW0zzxdhV9fMjmJbGgKvatGAk+dOqem+S5zn6D2mAqqqTRjQ1SfPbY227d6Sz0NgxpGnBqKr3tu1bRj0XSeOjqiZ/seSrVfX7w+eSXDKCKWlMuLpTC06SW+dSk6RX6co51qQ58UqaFqJzhw/al9meP6K5SJrnkrwf+CFgeZLrhk6dBLhqXMfMkKYFI8mVwOQPq0+uwArwNQY/iixJx+JpBs+jfYDB9y5Oeh74xZHMSGPB1Z1acJL8q6ryFoSk4yrJYr9vUceTIU0LUvvJllUMvhEcgKr65OhmJGm+SrKrqn4sycNMv3L8u0Y0Nc1zhjQtOEl+GvgQsILBt4NfCNxXVT8wynlJmp+SnF5VB5O8fbrzVfXFb/WcNB5c3amF6EPA3wW+WFXfD7wbODTaKUmar6rqYNv9EvBUC2UnAO9k8LyadEwMaVqIXqiqFwCSnFBVnwPeMeI5SZr/Pgm8IclyYA/wU8DNI52R5jVDmhaiA0neCvwhsDvJnfivXUmvXarqq8CPAr9VVT8CnDPiOWke8ys4tOC0P5wA/zLJnwAnAx8b4ZQkjYck+R7gg8CWVvP/Z3XM/I9HC06SpUOHD7etK2gkvVa/wOAXBj5aVY8k+XbgT0Y7Jc1nru7UgpPkC8AZwGEGS+TfChwEngV+pqoeesXOkjSLJG9h8NUbfzXquWh+85k0LUQfA36oqt5WVacA7wd2AT8HXD/SmUmat5J8Z5JPA58FHk3yUJJzZ+snvRJDmhai1VV1z+RBVX0c+L6q+l8Mls1L0rH4beCXqurtVXUm8MvA74x4TprHfCZNC9FEkn8G3NaOfxw4nGQR8Dejm5akee5NVfX/n0Grqk8kedMoJ6T5zStpWoj+IYNfG/jD9jqj1RYBPzayWUma7z6f5J8nWdlevwY8MepJaf5y4YAWrCRv9sFeScdL+03gXwfe20qfBH69qg6PblaazwxpWnCSfC/wEeDNVXVmkncCP1tVPzfiqUmah5K8AfjHwNkMvtZnR1V9fbSz0jjwdqcWomuB9cCXAarqz4DvG+mMJM1nO4HVDALa+4HfGO10NC5cOKAFqaqeSjJcemlUc5E0751TVd8JkOQm4IERz0djwpCmheipdsuzkrwe+HngsRHPSdL89f9vbVbVkSn/AJSOmc+kacFJ8jbgN4H3MfjFgY8DH6qqL490YpLmpSQvAX89eQicCHy17VdVnTSquWl+M6RJkiR1yNudWjCS/IsZTldVXf0tm4wkSbPwSpoWjCS/PE35TcAW4JSqevO3eEqSJL0iQ5oWpCRvAT7EIKDtAv5tVT072llJkvQyb3dqQUmyFPgl4IMMvtvou/02cElSjwxpWjCS/Abwo8CNwHf6k1CSpJ55u1MLRpK/AV4EjgDD/+G7TF6S1B1DmiRJUof87U5JkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDv0/smXFOX51mCIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_df['target'].value_counts().sort_index().plot(kind = 'bar', figsize = (10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only the tweets \n",
    "tweet_long_df_new = tweet_long_df.filter(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  is upset that he can't update his Facebook by ...\n",
       "2  @Kenichan I dived many times for the ball. Man...\n",
       "3    my whole body feels itchy and like its on fire \n",
       "4  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the dataframe\n",
    "tweet_long_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the tweets (every tweet in a new line) in a text file\n",
    "tweet_long_df_new.to_csv('longTweet.txt', sep='\\n', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe with only the labels\n",
    "tweet_long_df_new_label = tweet_long_df.filter(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the dataset description, the polarity of the tweets are saved in numeric form. 0 = negative, 2 = neutral, 4 = positive. However, the dataset from link 1 saves the polarity as such- N = negative, O = neutral, P = positive. To make the datasets of the same format, I am changing the polarity of the second dataset according to the first dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 0), 'target'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 2), 'target'] = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_long_df_new_label.loc[(tweet_long_df_new_label.target == 4), 'target'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target\n",
       "0            N\n",
       "1            N\n",
       "2            N\n",
       "3            N\n",
       "4            N\n",
       "...        ...\n",
       "1599995      P\n",
       "1599996      P\n",
       "1599997      P\n",
       "1599998      P\n",
       "1599999      P\n",
       "\n",
       "[1600000 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_long_df_new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the label tweets (every tweet in a new line) in a text file\n",
    "tweet_long_df_new_label.to_csv('twitterLabelBig.txt', sep='\\n', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to merge the tweets from the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to merge two files \n",
    "dataTweet = dataTweet2 = \"\" \n",
    "  \n",
    "# Reading data from first file \n",
    "with open('tweets_data.txt', errors='ignore') as fp: \n",
    "    dataTweet = fp.read() \n",
    "    with open('longTweet.txt', errors='ignore') as fp: \n",
    "        dataTweet2 = fp.read() \n",
    "# Merging two files into one another file \n",
    "dataTweet += \"\\n\"\n",
    "dataTweet += dataTweet2 \n",
    "with open ('totalTweet.txt', 'w') as fp: \n",
    "    fp.write(dataTweet)\n",
    "# Python program to\n",
    "# demonstrate merging\n",
    "# of two files\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merging the labels from the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to merge two files \n",
    "dataTweet = dataTweet2 = \"\" \n",
    "  \n",
    "# Reading data from first file \n",
    "with open('tweets_label.txt', errors='ignore') as fp: \n",
    "    dataTweet = fp.read() \n",
    "    with open('twitterLabelBig.txt', errors='ignore') as fp: \n",
    "        dataTweet2 = fp.read() \n",
    "# Merging two files into one another file \n",
    "dataTweet += \"\\n\"\n",
    "dataTweet += dataTweet2 \n",
    "with open ('totalLabel.txt', 'w') as fp: \n",
    "    fp.write(dataTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step combines the tweets with their polarity value. The prefix \"__label__\" is necessary for the fasttext format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine =[]\n",
    "\n",
    "with open(\"totalTweet.txt\") as xh:\n",
    "    with open('totalLabel.txt') as yh:\n",
    "        with open(\"totalLabelledTweet.txt\",\"w\") as zh:\n",
    "      #Read first file\n",
    "          xlines = xh.readlines()\n",
    "      #Read second file\n",
    "          ylines = yh.readlines()\n",
    "      #Combine content of both lists\n",
    "      #combine = list(zip(ylines,xlines))\n",
    "      #Write to third file\n",
    "          for i in range(len(xlines)):\n",
    "            line = \"__label__\"+ ylines[i].strip() + ' ' + xlines[i]\n",
    "            zh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command line code \"wc totalLabelledTweet.txt\" will give us the result of the word counts, line counts information which is in my case is 1600500 (line count or in this case number of tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to divide the datasets into train and test sets. I have created tweet.train and tweet.valid sets for training and testing purpose respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing fasttext library\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_supervised() will mostly be used for retruning a model object and calling test and predict on that object. This is the same as learning the text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"tweet.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input argument indicates the file containing the training examples. We can now use the model variable to access information on the trained model.\n",
    "\n",
    "We can also call save_model to save it as a file and load it later with load_model function.\n",
    "<br>source: https://fasttext.cc/docs/en/supervised-tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"model_tweet.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the classifier, model.predict() is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__N',), array([0.79193991]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Because I'm happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As happy is a positive word, it is labelled as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__P',), array([0.6295979]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"best\" is a positive word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__N',), array([1.00001001]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"I am sad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smilarly \"sad\" is a word discribing negative emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to test the model's quality on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.17850780437044744, 0.17850780437044744)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"tweet.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output are the number of samples (here 480500), the precision at one (0.643) and the recall at one (0.643)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.3333333333333333, 1.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"tweet.valid\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision at 5 is 0.333 and recall is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know that, precision discloses the number of correct labels among the labels predicted by fastText and the recall score is the number of successfully predicted labels among all the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__N', '__label__P', '__label__O'),\n",
       " array([7.91939914e-01, 2.08080098e-01, 1.00023208e-05]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Because I'm happy\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Betterment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A crude normalization can be obtained using the command line tools such as sed and tr and by using that, I removed the uppercase and punctuation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, I tried to train the new model on that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preprocssed = fasttext.train_supervised(input=\"tweetL.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6859001040582726, 0.6859001040582726)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preprocssed.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model betterment through increased epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_epochs = fasttext.train_supervised(input=\"tweetL.train\", epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.02251196670135276, 0.02251196670135276)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_epochs.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After increasing the number of epochs the model became quite strong. By setting up the epoch option, I increased the number of times each example is seen from default value 5 to 50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up larger learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_lr = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.05064724245577523, 0.05064724245577523)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision and recall score gets a bit down from the scores of increased epoch ( around 19%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned_lr1 = fasttext.train_supervised(input=\"tweetL.train\", lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6238834547346515, 0.6238834547346515)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr1.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know the range of lr is from 0.1 to 1.0. By applying lr=0.5, I could see that the scores decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying learing rate and increased epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameter_tuned = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.6116024973985432, 0.6116024973985432)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of sentiment analysis, using bigrams can be beneficial as word order can effect the accuracy of sentiment analysis. For example, In the sentence- \"I am not good at accounting.\" has the word \"good\" in it, it might be declared as positive but, using bigrams can be useful here as the word order \"not good\" will be taken into account and deemed as negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bigram = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.7501394380853278, 0.7501394380853278)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bigram.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential solution for faster training is to use hierarchical softmax instead of the regular softmax. This can be utilised with the option -loss hs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hisoftmax = fasttext.train_supervised(input=\"tweetL.train\", lr=1.0, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='hs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.631735691987513, 0.631735691987513)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hisoftmax.test(\"tweetL.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase rate in precision from bigram to Hierarchical softmax is 22.06% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchical softmax is a loss function that approximates the softmax with a much faster computation.\n",
    "\n",
    "The idea is to build a binary tree whose leaves correspond to the labels. Each intermediate node has a binary decision activation (e.g. sigmoid) that is trained, and predicts if we should go to the left or to the right. The probability of the output unit is then given by the product of the probabilities of intermediate nodes along the path from the root to the output unit leave.\n",
    "\n",
    "For a detailed explanation, you can have a look on this video.\n",
    "\n",
    "In fastText, we use a Huffman tree, so that the lookup time is faster for more frequent outputs and thus the average lookup time for the output is optimal.\n",
    "<br>\n",
    "Data Source: https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is beneficial when we want to assign multiple labels to the document. When we use independent binary classifiers for each label, it creates a convenient environment to handle multple labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multiClass= fasttext.train_supervised(input=\"tweetL.train\", lr=0.5, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__n',), array([1.00001001]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multiClass.predict(\"because I'm not happy\", k=-1, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480500, 0.3333333333333333, 1.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multiClass.test(\"tweetL.valid\", k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it shows that we are getting recall score 1.0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
